{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdPGoa3xaLvf/knRRU9sbU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanasyraf4/pyspark/blob/main/pyspark_tutorial_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPfEEHIcT3vU",
        "outputId": "a1a33864-b823-4b4c-b042-b85b1500323f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=c6230cf08bc1df95ac581d6fbf2b88d217129adac4ed4ca06809bc20ff652e12\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/My Drive/01. Data Stories vs Dashboard/pyspark data/test3.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqyhvZBXUBpl",
        "outputId": "cf9f11f0-1eaf-4f2b-8b4b-9e219d043068"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "vyimE2vFUDm1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Agg').getOrCreate()"
      ],
      "metadata": {
        "id": "T7ATkVzaUHdl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "mvjId_mpUIqd",
        "outputId": "6ecc6637-f9bc-4977-c64a-2feba92e5a62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc8d260e910>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://25731626a8b3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Agg</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv(path,header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "f4tr5qOBUK01"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoaBkaq_UM4l",
        "outputId": "c5c9d0f9-1ab9-466e-bee9-df9581d7d1c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_4MHYY6UN0m",
        "outputId": "5fa54937-d947-4276-9866-7677967787ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Groupby\n",
        "### Grouped to find the maximum salary\n",
        "df_pyspark.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU0IKVF3UPWF",
        "outputId": "11595acc-aaaf-4aa2-c539-2f2f8e5e30e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Name').avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sw0nMVpUQ9I",
        "outputId": "694a4ef4-8775-48b5-dedc-5528cdd1a855"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|     Name|       avg(salary)|\n",
            "+---------+------------------+\n",
            "|Sudhanshu|11666.666666666666|\n",
            "|    Sunny|            6000.0|\n",
            "|    Krish| 6333.333333333333|\n",
            "|   Mahesh|            3500.0|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Groupby Departmernts  which gives maximum salary\n",
        "df_pyspark.groupBy('Departments').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgbabWTxUTk1",
        "outputId": "3ac5969f-bb47-4601-d656-0aa920fca33b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      15000|\n",
            "|    Big Data|      15000|\n",
            "|Data Science|      43000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Departments').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEAsKsARUU2t",
        "outputId": "d4d1d59f-a977-43ab-d335-4b1102d5ebbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupBy('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B74OxmGhUVq_",
        "outputId": "1dae06f7-f868-4c62-9c23-c043ff8eb0ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.agg({'Salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDXEgWu8UWu9",
        "outputId": "4753d93a-aae8-4083-a1b8-044391b68f9d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}